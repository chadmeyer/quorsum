

\documentclass[letterpaper,11pt]{article}
\usepackage[top=1in, left=1.25in,right=1.25in,bottom=1.25in]{geometry}

\begin{document}

\title{Quorsum endgame strategic analysis}
\author{Chad D. Meyer \\ chad.meyer.120@gmail.com}
\date{\today}
\maketitle

\begin{abstract}
Quorsum is a racing game in which players attempt to move their pawns across
the board by rolling dice.  Additionally, pawns can only move on tiles of
their own colors.  Players can assign their limited dice to flipping tiles
and to moving their pawns toward their homes.  In this note, we discuss some
of the statistical and probablistic considerations surrounding late-game
decision making in a game of quorsum.
\end{abstract}

\section{Introduction}
Quorsum was introduced by Steve and Will Erickson in circa 2014.  Although
originally called an abstract strategy game, there is some debate whether the
random element of dice roling excludes quorsum from the category.  Nevertheless,
there is no hidden information, and players make their decisions based on the
board layout, current pawn positions and probablilities of rolling certain
numbers on their dice.

Recently, Erickson (2017) presented an analysis of the probabilities of
successfully moving $j$ spaces when starting with $n$ dice, which was analysed
using Markov theory to predict the expected number of turns to reach home.  This
has obvious implications to endgame strategy but is not enough to fully discuss
the possibilities.

This paper will be structured as follows.  In Secion 2, we outline the rules of
quorsum of relevance to our analysis.  In Secion 3, we will outline the results
of Erickson (2017).  In section 4, we analyze in great detail the probabilities
surrounding a specific move of interest.  In section 5, we introduce a Markov
model of Quorsum which includes tile flipping.  In secton 6, we exercise the
model on a number of examples.  In section 7, we discuss potential extentions
to the model.

\section{Rules of the game}
A Quorsum board is made up of a 4x4 grid of randomized, reversible (light and
dark) tiles which are numbered from 2 to 6.  Each player has two pawns which
start on a corner and are trying to move to the opposite corner.  Pawns can only
move onto tiles of the same color that they started on.  In order to
interact with a tile (either to flip it, or to move on to a tile) a player must
roll a die with a value greater-than or equal-to the number shown on that tile.

On a player's turn, they have 4 dice which they can allocate to moving their
pawns and/or flipping tiles.  They must declare how each of the dice are 
allocated before rolling and resolving any.  Any number (up to all 4) can be
allocated to any single action, or all 4 could be allocated to different
actions.  Once the dice are allocated, the player can choose to resolve them
in any order, but each action must be fully resolved before moving on.

Dice which are used to flip a tile are only rolled once.  If any one die shows
the number on the tile or higher, the tile is flipped.  Regardless of the
outcome these dice are no longer used until the next turn.  There is an
interesting mechanic which we will invoke later in this paper, whereby a tile
which has just been flipped cannot be immediately re-flipped by the opponent.
In addition to being important for defensive strategy, this will drive
two-turn offensive strategy as well.

When a player wishes to move a pawn, they must first declare which adjacent
tile (of the same color) they would like to move onto.  Note that they do not 
have to declare the entire path ahead of time, just the individual move.  They
then roll all of the dice which are available for moving the pawn.  If none of
the dice show a number greater than or equal to the target tile, the move is
over.  If, however, any of the dice are successful, the pawn moves onto this
tile.  Any dice which showed a lower number than the tile are removed, but
`"successful'' dice (showing a number greater than or equal to the tile) are
retained, and the pawn can move additional spaces using these.  The player may
end their action before they run out of dice if the path ahead is blocked (by
another pawn or a tile which is the wrong color) or if they wish to remain in
a particular location (usually defensively).

\section{Previous Results}
In Erickson (2017), a number of probabilities were derived, which we will
repeat here.  The probability of rolling $d$ dice and at least one die showing
a value greater than tile $t$ is
\begin{equation}
	s\left(d,t\right) = 1-\left(\frac{t-1}{6}\right)^d.
\end{equation}
The probability of exactly $k$ dice surviving when $d$ dice are rolled targeting
tile value $t$ is
\begin{equation}
	s_k\left(d,t\right)=\left(
	\begin{array}{c}
		d \\
		k
	\end{array} \right) \left(s\left(1,t\right)\right)^k
	\left(1-s\left(1,t\right)\right)^{d-k}.
\end{equation}
Now, given a "path" $\mathbf{t}$ (an array of $t$ values), the probability of
going at least $j$ steps along $t_1 \rightarrow t_\ell$ when starting with
$d_1$ dice is
\begin{equation}
	\hat{q}_j\left(d_1,\mathbf{t}\right) \sum_{d_1\geq\cdots\geq d_j\geq 1}
	\left( s\left(d_j,t_j\right)
	\prod_{m=1}^{j-1} s_{d_{m+1}}\left(d_m,t_m\right)\right)
\end{equation}
with the probability of ending exactly on tile j being
\begin{equation}
	q_j\left(d_1,\mathbf{t}\right)= \hat{q}_j\left(d_1,\mathbf{t}\right) -
	\hat{q}_{j+1}\left(d_1,\mathbf{t}\right).
\end{equation}
The sum above is over all valid sets of $j$ die rolls for which the first roll
is $d_1$ an the last is at least 1.  Finally, we define the probability of
starting on space $i$ and ending on $j$ as $q_{ij}(\mathbf{t})$, which can be
defined by setting the first $i$ values of $\mathbf{t}$ to 1 or by taking the
appropriate sub-portion of $\mathbf{t}$ for $j-i$ steps.

With these ingredients in hand we can define the transition matrix $Q$ for
$\mathbf{t}$ where entries are $Q_{ij}=q_{ij}$.  Markov theory then predicts
the expected number of turns and the probability of success in $N$ turns (see
Erickson (2017) section 4.4).  

\section{An illustrative example}
In this section we will look into the probabilities associated with  generalize the results of Erickson (2017) to include
the potential need to flip a tile.  No concern of balancing actions between two
pawns/paths will be discussed yet.

Our first building block will be a composite move of flipping a tile and
moving on to it.  We will need to consider probabilities over multiple turns
for completeness.  This is where the ``guarded'' state of a newly-flipped tile
comes in.  But first, we consider single-turn probabilities.  What is the
probability of both successfully turning over a tile $t$ using $d_t$ dice and
then successfully moving on to it using $d_m$ dice?  The probability of
flipping is simply $s(d_t,t)$ and the probability of moving is $s(d_m,t)$,
therefore the probability of advancing in this way is $s(d_m,t)s(d_t,t)$.
Assuming we had 4 dice at our disposal, the single turn maximum would be
$d_m=d_t=2$.  

The two-turn probabilities are more interesting.  Let us take,
as a motivating example, trying to flip-move onto a 6-tile.  In the first case,
we take $d_m=d_t=2$ for two turns, and for the second, we devote all 4 dice in
the first turn to flip the tile and all four to move.  Recall that $s(2,6) = 
0.305555$ and $s(4,6)=0.5177$.  In this first case there are three distinct
outcomes: the flip fails (and thus the move is negated), the flip succedes and
the move fails (but the tile is flipped for next time) and both the flip and
the move are successful.  This is an easily brute-force calculated quantity.
The probabilities are as follows:
\begin{enumerate}
\item Great success! Turn 1 flip-move worked! 0.09334
\item Partial success initially: at least it flipped: 0.2122
\begin{itemize}
\item Next turn success: 0.5177, for a product of 0.1099
\item Next turn failure = partial advancement over all: 0.1023
\end{itemize}
\item The flip failed so turn 1 was a waste: 0.6944
\begin{itemize}
\item Next turn success: same odds as above, for a product of 0.06483
\item Partial success: flipped the tile but still couldn't move: 0.1474
\item Utter failure: 0.4822
\end{itemize}
\end{enumerate}
In summary, 9.3\% of the time you will be successful on the first turn (and
thus able to do something different on the second turn), 17.5\% of the time, you
will not move the first time, but will at least move the second, 25\% of the
time you will have at least flipped the first tile, and 48\% of the time you
will be exactly where you started.

Now, let us consider our second strategy, namely devoting all four dice to
flip initially, and then when successful, devoting all four dice to move.  For
comparison purposes, let us assume that we roll to flip the second time if we
were unsuccessful the first time.
\begin{itemize}
\item flip, then move: 0.2681
\item flip, then could not move: 0.2497
\item did not flip, then flip: 0.2497
\item failed to flip both times: 0.2326
\end{itemize}
Now, here we see something surprising!  The odds of success in the first
strategy are exactly the same as those in the second!  (Note that this result
holds for all values of $t$ and is not unique to $t=6$.)  The other odds,
however, are different.  In strategy 1, about once every 11 tries, your pawn
will advance in your first turn (which will never happen in strategy 2) but
half of the time, you will be no better off than you were.  In strategy 2,
about half of the time the tile will at least be flipped, which is better than
in strategy 1.

But, we must consider another strategy, which I will term 2b.  In this strategy,
we are desperate to end the game, as this is our last move to home.  We use
all four dice to flip as in strategy 2, but if unsuccessful, we revert to
strategy 1's splitting the dice into 2 and 2.  In this case the results are
\begin{itemize}
\item flip, then move: 0.2681
\item flip, then could not move: 0.2497
\item did not flip, then flip-move: 0.04503
\item failed to flip, then only flipped: 0.1023
\item failed to flip, then failed to flip: 0.3349
\end{itemize}
Here, we managed to glean an extra 4.5\% out of the system by taking advantage
of the fact that if we failed the first time, there was still (even minimal)
hope of still ending the game.

Some remarks are in order.  Whereas it is true that strategy 2b has the greatest
\textit{situational} probability of succeeding (the situation being that the 
player wants to maximize the likelihood of winning in exactly 2 turns), if this
move is the first, rather than the last, of the path $\mathbf{t}$ it is probably
not the best strategy.  It remains to be shown whether strategy 1 or 2 would 
always be best or in what situations would either be the best, but we will
examine these after further development of the Markov model of quorsum.

\section{An Extended Markov Model for 1 pawn systems}
In Erickson (2017), the definition of the single pawn, single color path was
shown to be Markovian.  In this section, I propose to extend that description
to include the possibility of color-shifted tiles.

In order to be Markovian, the probability of going from one ``state" to another
``state" must only be dependent on the present state and not be dependent on
any past history.  Quorsum (at least in single pawn, strictly offensive mode)
therefore qualifies as Markovian.  An essential aspect of carrying out various
statistical analyses of Quorsum will require constructing a transition matrix
identifying the probabilities that, in a given turn, the path + pawn state will
transition from one state to another, which is encapsulated in the transition
matrix $Q$.  This requires the definition of a \textit{strategy}.  A strategy,
loosely defined, is an algorithm for choosing which actions to take given the 
current state.  A strategy could be very complicated or very simple.  For
Quorsum, the strategy includes where the pawn `wants' to go and how dice will
be assigned.  Once a strategy is in place, it is possible to calculate the
elements of the transition matrix.  Thus, the problem had been adjusted to
optimizing a measure over possible strategies.  Note that the strategy
employed in the previous paper was ``devote all four dice to moving always".

Recall from previous that we defined our state array $\mathbf{t}$ using the path
of tiles the pawn must traverse.  Thus, the state could be defined as "the
position of the pawn along the path", which we will call $\mathcal{P}$.  When
we consider the possible need to flip some tiles, me must also include the 
state of the board/path, $\mathcal{Q}$, which corresponds to the set of all 
accessible tile orientations.  Thus, the size of the system is $\mathcal{P}
\otimes \mathcal{Q}$ where some of the states are inaccessable.

\subsection{Defining the state}
Now, we propose to define a limited state set which completely describes the
single-pawn system.  Here are the assumptions we are making in this sub-section
\begin{enumerate}
	\item The path the pawn will follow is fixed, and single (there is no
		alternate path that could be considered, for instance, if a
		tile flip failed one might still be able to move (even if at
		a low probability).
	\item The pawn will not move backwards.
	\item Only wrong-colored tiles will be flipped and only and exactly
		once and must be flipped before the pawn moves to them.
	\item Flips are always evaluated before movement
\end{enumerate}
Note that some of these assumptions could be relaxed in
the future.  

We first define $\mathbf{t}$, the path the pawn will take.
These are the tile values.  As said above, let us assume there is a single
path we will follow.  This defines $\mathcal{P}$ which is length $\ell+1$ where
$\ell$ is the length of $\mathbf{t}$.  Next, we identify the $n\leq \ell$ 
tiles which need to be flipped, at unique locations $1\leq l_1 < l_2 < \cdots < l_n \leq \ell$.  There are
$2^n$ possible states of the board.  Naively, one may think that there are
$2^n(\ell+1)$ possible states, but some of those are not accessable given our
above assumptions.  One can think of $\mathcal{Q}$ as an $n$-dimensional space
(with two states in each dimension).  This dimensionality is reduced by 1
for each $l_i$ crossed.  Thus, if we define $l_0=0$ and $l_{n+1}=\ell+1$ for
convenience, we can arive at the general formula for number of accessible
states.
\begin{equation}
	\left\{\mathcal{S}\right\} = \sum_{i=0}^{n} (l_{i+1}-l_i)2^{n-i}
\end{equation}
Given that $\ell$ is $\mathcal{O}(6)$ at the starting point even if every tile
needed to be flipped, the total size of $\mathcal{S}$ is only 127, which seems
quite tractable.  If this is truly an endgame analysis, $\ell$ is more like 3-4
with a maximum total size of 31.  There will also be the possibility, for a
given strategy, that some otherwise possible states in $\mathcal{S}$ will never
be accessed, and these would need to be handled properly in the analysis as
well.

\subsection{The Strategy}
At this point, we must rigorously define what we mean by ``strategy''.  Given
a particular state $\mathcal{S}_i$, a strategy yields a unique allocation of
the dice.  This is sufficient for our assumptions above.  However, to be more
general, a strategy is a perscription for all player choices given 
$\mathcal{S}_i$.  In a general game of Quorsum that could include which order
resolve each action, which tile to move to, etc.

A strategy could be simple (always roll 4 to move until you hit a block, then
always roll 4 to flip, repeat), or complicated (involving many ancillary
conditions and evaluations).  We will defer discussion on \textit{specific}
strategies until later.  

\subsection{The Markov Model}
We have already established that this is Markovian.  Given path $\mathbf{t}$,
flipped tile positions $\{l_i\}|_{i=1\cdots n}$ and a strategy, we must
construct the transfer matrix $Q_{ij}$.

Let us define a mapping function
$R(p,\mathbf{q})\rightarrow i$ which maps position $p$ and board state 
$\mathbf{q}$ to index $i$, and its inverse 
$R^{-1}(i)\rightarrow(p,\mathbf{q})$.  Note, we are
making $\mathbf{q}$ an $n$-dimensional array (or you could think of it as an
n-digit binary number) with components $q_r|r=1\cdots n$ where $q_r=0$ is a
tile which needs to be flipped.  

Now, we can
construct $Q_{ij}$.  We will label $R^{-1}(i) = (p_i, \mathbf{q}_i)$.  Strategy
dictates the dice distribution: $(d_m;d_{f,r})$ where $d_{f,r}$ is the number
of dice assigned to flip the tile at position $l_r$.  Note that our strategy
requires $l_r>p_i$ and $q_{i,r}=0$.
\[
	Q_{ij} = P(\mathbf{q}_i\rightarrow\mathbf{q}_j)P(p_i \rightarrow p_j;\mathbf{q}_j)
\]
with
\[
	P(\mathbf{q}_i\rightarrow\mathbf{q}_j)=\prod_{r=1}^{n} 
	\left\{
		\begin{array}{lrl}
			s(d_{f,r},t_{l_r}) & ; & q_{i,r} \neq q_{j,r} \\
			\left(1-s(d_{f,r},t_{l_r})\right) &;& q_{i,r} = q_{j,r}
		\end{array}
	\right. 
\]
and
\[
	P(p_i \rightarrow p_j;\mathbf{q}_j)=q_{p_j}(d_m,\bar{t}_{p_i}^{\mathbf{q}_j})
\]
where the $q_{p_j}$ function is equation 4.  The modified sequence 
$\bar{t}_{p_i}^\mathbf{q_j}$ is such that $t$ from 1 to $p_i$ is set to 1 and
$t_{l_r}$ is set to 7 when the tile still needs flipping (i.e. $q_{j,r}=0$).
This is sufficient to completely define the system.

\section{Examples}
Now that we have defined the transition matrix $Q_{i,j}$, let's use it!  Note
here that in isolating the transient sub-matrix $Q_T$, in addition to removing
the terminal state, we may need to remove other states which appear but are
not reachable from the initial state.  

\subsection{Terminal 6}
We will first revisit our example from above, now specifying that we just
have to take the final step to win.  This is a three state system: unflipped
(0), flipped (1) and home (2).  The transient matrix will be a 2x2 system.
Recall that this analysis compares strategies and so we will consider multiple
strategies in turn.  Note that strategy 2b is not really Markovian, since
there is a state-independent driver (number of turns in which you want to be
successful). 

\subsubsection{Strategy 1}
First we consider splitting our die rolls into 2 to flip and 2 to roll.  In
this case, our transition matrix looks like 
\[
   Q = \left(\begin{array}{ccc}
      0.6944 & 0.2122 & 0.0934 \\
      0 & 0.4823 & 0.5177 \\
      0 & 0 & 1
      \end{array} \right)
\]
Now, $Q_T$ is just the upper-right 2x2 system, so $(I-Q_T)^{-1}$ is 
\[
   (I-Q_T)^{-1} = \left(\begin{array}{cc}
     2.9797 & 1.2214 \\
     0 & 1.916
   \end{array} \right)
\]
and so in this case the expected number of turns to success is 4.2.  The
probability of success in $n$ turns is: [0.0934, 0.265, 0.431, 0.567,
0.669,0.744].  Therefore, even though the ``expected number of turns" is a
little over 4, there is still a better than 25\% chance that you won't be
home in 7 turns with this strategy!

\subsubsection{Strategy 2}
In this strategy, we devote 4 dice to flipping and then 4 to moving (once
successful).  The transition matrix is now
\[
   Q = \left(\begin{array}{ccc}
      0.4823 & 0.5177 & 0 \\
      0 & 0.4823 & 0.5177 \\
      0 & 0 & 1
      \end{array} \right)
\]
and $Q_T$ is a simpler looking matrix
\[
   (I-Q_T)^{-1} = \left(\begin{array}{cc}
     1.931 & 1.931 \\
     0 & 1.931
   \end{array} \right)
\]
Now, in this case the expected number of turns is 3.86, more than a quarter
turn faster than strategy 1.  Further, the odds of success in $n$ turns is
[0, 0.268, 0.527, 0.714, 0.834, 0.906, 0.948].  Now, there is only a 5\%
chance that you won't be home by turn 7.  Obviously this is the better
overall strategy.

\subsection{Early 6}

\section{Extention to multi-pawn and multi-player}
The full Quorsum system with 4 pawns each seeking different homes, and a 4x4
grid of tiles is enormously large.  The board itself has $2^{16}$ different
configurations and with 4 pawns on the board this numnber swells to 
$2^{16} 64!/(64-4)! = 999,360,036,864 \sim \mathrm{1 trillion}=\mathcal{Q}$.
Good luck finding a machine to store a trillion by trillion matrix, let alone
invert it.  Of course, many of the states are completely inaccessable for a
given board (pawns cannot be on a tile which does not match their color)
and strategy (there are certain tiles where a player would never go), but
nevertheless, a full analysis of the system is cumbersome.

In the following sub-sections I will outline how we could further extend the
model in specific ways.  Each could be done separately or in conjunction with
each other. 

\subsection{Adding defense}
One possible single-player extension could be to model defensive strategy as
well.  This might be interesting, because a more aggressive offensive strategy
might be better if the player had to worry that the tiles might be flipped (and
thus `locked' in place).

This brings up an interesting complication, because Markov theory requires the
transition probabilities to be independent of past history, but it would seem
that the locking mechanism violates that.  However, in this case, we could
extend the definition of $\mathcal{Q}$ to include knowledge of whether a tile
is locked or not.  In the single-player case we are considering, our binary 
$q_i$ must become at least trinary (for instance, 0 means `needs to be flipped,
and could be flipped', 1 means `flipped and can be move to,'
and 2 means `needs to be flipped but cannot this turn').  In that case we
would need to evaluate the probabilities of defensive interference with the
extant knowledge that we have just flipped a tile.  In that case, when we
evaluate the probability of transitioning from state $i$ to $j$ we also 
(potentially) calculate whether to transition from j to a different state.
This must be calculated specifically as a modification of of $Q_{ij}$.

Additionally, every tile will need to be potentially flippable, which could
greatly increase the complexity of the problem.

This could also be implemented in a relatively straightforward way.  If we were
willing to include all four tile states (both colors, locked or not), then it
would be as simple as formulating a defensice transition matrix (the defense,
seeing the state of the board, would potentially devote a few dice to defensive
actions.  Then, instead of using 
$Q_{ij}$, we use $\tilde{Q}_{ij} = Q_{ik}D_{kj}$ where $D_{kj}$ is just the
transition matrix on defense.  How we build $D$ is left as an exercise for the
reader, but if you made it this far, I have full confidence in you!  A word of
warning: in this case, the player should never encounter a tile flipped to
their preferred position and locked, thus those states only serve as
intermediate states so that $D$ could be represented as a matrix (representing
a $k$-state dependent strategy).

\subsection{Including both player pawns}
Let's assume the application here is endgame where the player pawns have
passed each other and will not get in each others' way.  Strategy is still
assigning dice, but there are now two potential pawns to move.  $\mathcal{Q}$ 
is now the union of both paths, and $\mathcal{P}$ is $\mathcal{P}_1\otimes
\mathcal{P}_2$.  The dimensionality of the problem is increased dramatically,
but if we limit the paths to be short it may still be tractable.  Though the
system is slightly more complicated, defining motion in state space is really
quite easy.  If the two independent paths are length $j$ and $k$, $\mathcal{P}$
has size $(j+1)(k+1)$ and the number of states in each case is still given by
(5).  The product of the two is the size of the system.  If $i=j=3$, and all of
the tiles need to be flipped, there are $15^2=225$ independent states, which is
also tractable.

Now, if the pawns can interact (as when they need to pass through the middle)
this greatly complicates all of our considerations.  The system is no longer
decomposable.  Even without flipping tiles, there are $j(j-1)$ possible
position states for $j$ tiles.  If some flipping is needed (or mandatory)

\subsection{Including a non-unique (fat) path}
Here, let's consider what I will term a fat path.  In this case we include
possible either-or directions.  As an example consider a pawn two spaces from
home (diagonally adjacent) one path includes a wrong-color 2 and the other
includes a correctly-colored 6.  The player might likely try to flip the 2 with
one die and move with the other three, but if the flip failed, you can believe
that the player will roll the dice on the off chance that they rolled a 6
because they would be in the same boat at the end of it all.  What if the
numbers were 3 and 5, what is the best distribution of dice in that case?
This is the sort of question that the model could address relatively easily;
there being one additional state with a non-zero probability of being accessed
(if you happened to fail to roll the 2).  If the path became too fat, the state
space could become too large (or defining the strategy in this case could be
quite difficult).

One approach that seems reasonable is to define a main path and one or more
``excursions'' which connect two points on the main path via a different route.
This isn't absolutely general, but probably covers many useful situations.

\subsection{Including both players}
Are you a massochist?

\section{Extending the analysis}
Up to now, we have only discussed extending the definition of ``system'' to 
include flipped tiles (and mentioned some other things above).  Otherwise, the
analysis hasn't included anything novel.  In this section, we propose to change
that.  

Recall that we have defined the matrix $Q$ such that $Q_{ij}$ is the
probability, given our strategy, of transitioning from state $i$ to state $j$ in
one turn.  We reduce the system to $Q_T$ by eliminating any stationary states
(rows and columns where the diagonal entry is 1, for instance the final state)
and other inaccessible states (states which could never be reached from the
initial state with any probability).  From this we define the principle
matrix $T=(I-Q_T)^{-1}$.  This is also called the transmission matrix, and its
entries are $T_{ij}=$ the expected (average) number of turns spent in state $j$
when starting at state $i$ after having taken an infinite number of turns.

This is just the first moment (average) and doesn't tell us everything.  Note
above that although our two different strategies of moving onto a 6-tile only
differed by about 1/4 turn, examining the probabilities twice as many turns 
later showed that things looked a lot worse than that for the first strategy.

This opens up the idea of the higher order moments of the system.  The process
described in our analysis is roughly Poisson in nature and not generally
Gaussian.  If we took a sufficient number of turns, the statistics would look
Gaussian, but we would also probably be violating certain assumptions we made in
forming the system.  All that said as a disclaimer, the higher moments of the
system are the variance, skewness, kurtosis, etc., and they describe the shape
of the probability distribution.  Roughly, the variance describes the width
of the distribution (how good of a guess the expected turns is), the skewness
describes whether the distribution leans one way or the other and the kurtosis
describes how heavy the tails of the distribution are.

\appendix
\section{Implemention Notes}
We've devoted quite a bit of space to defining various transition matrices and
how they might be used to evaluate strategies, but very little to the practical
details of how this all could work in reality.  As usual, we relegate such
comments to an appendix.

\subsection{State Ordering}
In complicated systems as described above (where there could be 100s of states)
it is certainly useful to more carefully order your states.  I like to place
the initial state (all pawns unmoved, initial tile locations) first.  This
allows me to quickly scan the first row of $Q$ and $Q^N$ to assess probabilities
and likewise 

\end{document}
